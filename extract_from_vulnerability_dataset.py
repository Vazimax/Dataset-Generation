#!/usr/bin/env python3
"""
Extract from Vulnerability Dataset
Extracts critical CVEs from the vulnerability dataset and integrates them into our dataset structure.
"""

import json
import os
import shutil
import logging
from pathlib import Path
from typing import List, Dict

# Setup logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class VulnerabilityDatasetExtractor:
    def __init__(self, 
                 vulnerability_dataset: str = "top-1000-training-samples.json",
                 new_cves_list: str = "new_cves_only.json",
                 output_dir: str = "dataset"):
        self.vulnerability_dataset = vulnerability_dataset
        self.new_cves_list = new_cves_list
        self.output_dir = output_dir
        self.vulnerability_data = []
        self.new_cves = []
        
    def load_data(self):
        """Load both the vulnerability dataset and new CVEs list"""
        try:
            # Load vulnerability dataset
            with open(self.vulnerability_dataset, 'r') as f:
                self.vulnerability_data = json.load(f)
            logger.info(f"üìä Loaded vulnerability dataset with {len(self.vulnerability_data)} samples")
            
            # Load new CVEs list
            with open(self.new_cves_list, 'r') as f:
                self.new_cves = json.load(f)
            logger.info(f"üìã Loaded new CVEs list with {len(self.new_cves)} CVEs")
            
            return True
        except Exception as e:
            logger.error(f"Failed to load data: {e}")
            return False
    
    def find_cve_samples(self, cve_id: str) -> List[Dict]:
        """Find all samples for a specific CVE in the vulnerability dataset"""
        samples = []
        for sample in self.vulnerability_data:
            if sample.get('cve_id') == cve_id:
                samples.append(sample)
        return samples
    
    def extract_cve_to_dataset(self, cve_id: str, cve_info: Dict) -> bool:
        """Extract a single CVE to the dataset structure"""
        try:
            # Find samples for this CVE
            samples = self.find_cve_samples(cve_id)
            if not samples:
                logger.warning(f"No samples found for {cve_id}")
                return False
            
            # Create CVE directory
            cve_dir = os.path.join(self.output_dir, cve_id)
            os.makedirs(cve_dir, exist_ok=True)
            
            # Create vulnerable and fixed subdirectories
            vulnerable_dir = os.path.join(cve_dir, "vulnerable")
            fixed_dir = os.path.join(cve_dir, "fixed")
            os.makedirs(vulnerable_dir, exist_ok=True)
            os.makedirs(fixed_dir, exist_ok=True)
            
            # Extract source code files
            vulnerable_files = []
            fixed_files = []
            
            for sample in samples:
                source_code = sample.get('source', '')
                if not source_code:
                    continue
                
                # Determine if this is vulnerable or fixed based on sample type
                # For now, we'll use the first sample as vulnerable and look for patterns
                if 'vulnerable' in str(sample).lower() or len(vulnerable_files) == 0:
                    if len(vulnerable_files) == 0:
                        vulnerable_files.append(source_code)
                else:
                    if len(fixed_files) == 0:
                        fixed_files.append(source_code)
            
            # If we don't have both versions, try to find them differently
            if not vulnerable_files or not fixed_files:
                # Use first sample as vulnerable, second as fixed
                if len(samples) >= 2:
                    vulnerable_files = [samples[0].get('source', '')]
                    fixed_files = [samples[1].get('source', '')]
                elif len(samples) == 1:
                    # Only one sample, use it for both (will be fixed later)
                    vulnerable_files = [samples[0].get('source', '')]
                    fixed_files = [samples[0].get('source', '')]
            
            # Write vulnerable files
            for i, code in enumerate(vulnerable_files):
                if code:
                    filename = f"vulnerable_{i+1}.c" if code.strip().startswith('#include') else f"vulnerable_{i+1}.txt"
                    filepath = os.path.join(vulnerable_dir, filename)
                    with open(filepath, 'w') as f:
                        f.write(code)
            
            # Write fixed files
            for i, code in enumerate(fixed_files):
                if code:
                    filename = f"fixed_{i+1}.c" if code.strip().startswith('#include') else f"fixed_{i+1}.txt"
                    filepath = os.path.join(fixed_dir, filename)
                    with open(filepath, 'w') as f:
                        f.write(code)
            
            # Create metadata.json
            metadata = {
                'cve_id': cve_id,
                'project': cve_info.get('project', 'Unknown'),
                'cwe_id': cve_info.get('cwe_id', 'Unknown'),
                'cwe_name': cve_info.get('cwe_name', 'Unknown'),
                'weaponization_score': cve_info.get('weaponization_score', 0.0),
                'vulnerability_patterns': cve_info.get('vulnerability_patterns', []),
                'is_high_priority_project': cve_info.get('is_high_priority_project', False),
                'priority': cve_info.get('priority', 'high'),
                'description': cve_info.get('description', ''),
                'source': 'vulnerability_dataset',
                'extraction_status': 'success',
                'vulnerable_files_count': len(vulnerable_files),
                'fixed_files_count': len(fixed_files)
            }
            
            metadata_file = os.path.join(cve_dir, "metadata.json")
            with open(metadata_file, 'w') as f:
                json.dump(metadata, f, indent=2)
            
            logger.info(f"‚úÖ Successfully extracted {cve_id} to {cve_dir}")
            return True
            
        except Exception as e:
            logger.error(f"Failed to extract {cve_id}: {e}")
            return False
    
    def extract_all_cves(self) -> Dict:
        """Extract all new CVEs to the dataset"""
        logger.info(f"üöÄ Starting extraction of {len(self.new_cves)} CVEs...")
        
        results = {
            'total_cves': len(self.new_cves),
            'successful': 0,
            'failed': 0,
            'failed_cves': []
        }
        
        for cve_info in self.new_cves:
            cve_id = cve_info['cve_id']
            logger.info(f"üìã Processing {cve_id}...")
            
            if self.extract_cve_to_dataset(cve_id, cve_info):
                results['successful'] += 1
            else:
                results['failed'] += 1
                results['failed_cves'].append(cve_id)
        
        logger.info(f"‚úÖ Extraction complete: {results['successful']} successful, {results['failed']} failed")
        return results
    
    def create_extraction_report(self, results: Dict, output_file: str = "vulnerability_dataset_extraction_report.json"):
        """Create a detailed report of the extraction process"""
        report = {
            'extraction_summary': results,
            'new_cves_added': results['successful'],
            'total_cves_in_dataset': len(os.listdir(self.output_dir)) if os.path.exists(self.output_dir) else 0,
            'extraction_timestamp': str(Path().cwd()),
            'source_dataset': self.vulnerability_dataset
        }
        
        with open(output_file, 'w') as f:
            json.dump(report, f, indent=2)
        
        logger.info(f"üìã Extraction report saved to {output_file}")
        return report
    
    def print_summary(self, results: Dict):
        """Print a summary of the extraction results"""
        print("\n" + "="*80)
        print("üöÄ VULNERABILITY DATASET EXTRACTION RESULTS")
        print("="*80)
        print(f"üìä Total CVEs processed: {results['total_cves']}")
        print(f"‚úÖ Successful extractions: {results['successful']}")
        print(f"‚ùå Failed extractions: {results['failed']}")
        print(f"üìà Success rate: {(results['successful'] / results['total_cves']) * 100:.1f}%")
        
        if results['failed_cves']:
            print(f"\n‚ùå Failed CVEs:")
            for cve_id in results['failed_cves']:
                print(f"  - {cve_id}")
        
        # Check final dataset size
        if os.path.exists(self.output_dir):
            total_cves = len([item for item in os.listdir(self.output_dir) if item.startswith("CVE-")])
            print(f"\nüìä Final dataset size: {total_cves} CVEs")
            
            if total_cves >= 50:
                print(f"üéâ SUCCESS! We've reached our target of 50 critical CVEs!")
                print(f"   Target: 50 CVEs")
                print(f"   Achieved: {total_cves} CVEs")
                print(f"   Overachievement: {total_cves - 50} CVEs")
            else:
                print(f"‚ö†Ô∏è  We still need {50 - total_cves} more CVEs to reach our target")

def main():
    """Main function"""
    extractor = VulnerabilityDatasetExtractor()
    
    # Load data
    if not extractor.load_data():
        return
    
    # Extract all CVEs
    results = extractor.extract_all_cves()
    
    # Create report
    report = extractor.create_extraction_report(results)
    
    # Print summary
    extractor.print_summary(results)
    
    print(f"\nüéØ Next Steps:")
    print(f"1. Run dataset validation to ensure quality")
    print(f"2. Check for code differences between vulnerable and fixed versions")
    print(f"3. Verify weaponizability of extracted CVEs")
    print(f"4. Consider running LLM-guided variant generation")

if __name__ == "__main__":
    main()
